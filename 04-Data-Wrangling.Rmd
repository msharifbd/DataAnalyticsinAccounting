# Data Wrangling

Data wrangling is the process of cleaning data, so that data become ready for further manipulation such as visualization and modeling. Sometimes, data wrangling is also called `data munging`. More specifically, data wrangling involves transforming and mapping data frome one from to another form - particularly from *raw* form to *tidy* form.

There is an old saying that 90% of data science involves data wrangling. In many cases, data wrangling is difficult as it involves dealing with missing entries, ambiguous values, and different types of mixed data. In data analytics ecosystem in `R`, data wrangling involves three jobs - importing data into `R`, cleaning (tidying) the data, and tranforming the data. 

```{r fig.align='center', echo=FALSE, fig.cap= "Data Wrangling in R"}
knitr::include_graphics('images/data-science-wrangle.png', dpi = NA)
```

The first job - importing data into `R` - is discussed in chapter 03. In this chapter, cleaning (tidying) the data in `R` will be discussed. The last job will be discussed in next chapter - Exploratory Data Analysis (EDA). 

## `tidy` data 

Data wrangling or data munging results in `tidy` data - which is storing data that makes further manipulation on data such as transformation, visualization, and modeling easier. The following rules make a dataset `tidy` - 

* Each variable must have its own column
* Each observation must have its own row
* Each value must have its own cell

## Same Data, but Different Formats (Presentations)


## Tidying Messy Data

According to Hadley Wickham, "Tidy datasets all alike, but every messy dataset is messy in its own way" [@wickham_r_2017]. Messy data can be in many forms; for example - Wickham [-@wickham_tidy_2014] mentions the five *most common problems* with messy datasets. These problems include - 

* Column headers are values, not variable names
* Multiple variables are stored in one column
* Variables are stored in both rows and columns
* Multiple types of observational units are stored in the same table
* A single observational unit is stored in multiple tables

### Column Hearders are Values, not Variable Names

The following dataset is an example of this case, in which the name of the variables (columns) are numbers. Though in some cases, this data format might be useful, in many cases usually it is not useful. Below is an example of such type of dataset.  


```{r echo=FALSE, message= FALSE, warning=FALSE}
library(tidyverse)
mobile <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-11-10/mobile.csv')
variable_number <- mobile %>%
  filter(year %in% 2000:2005) %>% 
  slice(1:100) %>% 
  select(entity,continent,year,mobile_subs) %>%
  pivot_wider(names_from=year, values_from=mobile_subs)
variable_number
```

### Multiple Variables are Stored in One Column





## `tidyr` Package for `tidy` Data 

The `tidyr` package is widley used to `tidy` data in `R`. Specifically, `pivot_longer`, `pivot_wider`, `separate`, and `extract` functions are widely used to make a messy data into `tidy`. 


### `pivot_longer` function 

If the dataset above (Column headers are values, not variable names) is made `tidy` using `pivot_longer` function, then it will be look like this (Assuming the name of the dataset is variable_number) - 

```{r}
# using pivot_longer () function 
variable_number %>% 
  pivot_longer(cols = -c("entity", "continent"),
               names_to = "year",
               values_to = "mobile_subs"
               )
```

There are several arguments of `pivot_longer` function. Here three arguments are used. The `cols` argument specifies which columns should (not) be used in `pivot_longer` function. In this case, we select the variables that should not be used while using `pivot_longer` function. The second argument `names_to` specifies the name of the variable in which existing column values will be stored and finally `values_to` specifies the name of the column in which the cell values will be stored. Now, the dataset is a `tidy` dataset as it complies with the rules of `tidy` dataset. 

This is a very good source to discuss about data wrangling - <https://dsapps-2020.github.io/Class_Slides/>

The above link is also best about why `EXCEL` is not be best for Accounting & Audit Analytics. 
